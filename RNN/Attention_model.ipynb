{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2023-12-08 13:55:04.482856: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-08 13:55:04.541250: I tensorflow/tsl/cuda/cudart_stub.cc:28] Could not find cuda drivers on your machine, GPU will not be used.\n",
      "2023-12-08 13:55:04.542257: I tensorflow/core/platform/cpu_feature_guard.cc:182] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2023-12-08 13:55:05.675159: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    }
   ],
   "source": [
    "from keras.layers import Input , Dense , LSTM , Attention , Embedding , dot ,concatenate\n",
    "from keras.models import  Model\n",
    "from keras.preprocessing.text import  Tokenizer\n",
    "from keras.preprocessing.sequence import  pad_sequences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "french_sentences = ['Bonjour', 'Comment ça va?', 'La vie est belle']\n",
    "english_sentences = ['Hello', 'How are you?', 'Life is beautiful']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "french_tokenizer = Tokenizer(filters='')\n",
    "english_tokenizer = Tokenizer(filters='')\n",
    "\n",
    "french_tokenizer.fit_on_texts(french_sentences)\n",
    "english_tokenizer.fit_on_texts(english_sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'bonjour',\n",
       " 2: 'comment',\n",
       " 3: 'ça',\n",
       " 4: 'va?',\n",
       " 5: 'la',\n",
       " 6: 'vie',\n",
       " 7: 'est',\n",
       " 8: 'belle'}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "french_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{1: 'hello', 2: 'how', 3: 'are', 4: 'you?', 5: 'life', 6: 'is', 7: 'beautiful'}"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "english_tokenizer.index_word"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_french_len = max([len(sentence.split()) for sentence in french_sentences])\n",
    "max_english_len = max([len(sentence.split()) for sentence in english_sentences])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_french = french_tokenizer.texts_to_sequences(french_sentences)\n",
    "X_french = pad_sequences( X_french , maxlen=max_french_len , padding=\"post\")\n",
    "\n",
    "Y_english = english_tokenizer.texts_to_sequences(english_sentences)\n",
    "Y_english = pad_sequences( Y_english , maxlen=max_english_len , padding=\"post\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([[1, 0, 0, 0],\n",
       "        [2, 3, 4, 0],\n",
       "        [5, 6, 7, 8]], dtype=int32),\n",
       " array([[1, 0, 0],\n",
       "        [2, 3, 4],\n",
       "        [5, 6, 7]], dtype=int32))"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_french ,Y_english"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "len_french_word_corpus = len(french_tokenizer.word_index) + 1\n",
    "len_english_word_corpus = len(english_tokenizer.word_index) + 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "latent_dim = 64\n",
    "\n",
    "encoder_inputs = Input(shape=(max_french_len,))\n",
    "encoder_embedding = Embedding(input_dim=len_french_word_corpus ,output_dim=latent_dim)(encoder_inputs)\n",
    "encoder_lstm = LSTM(latent_dim ,return_sequences=True ,input_length=encoder_embedding)\n",
    "\n",
    "decoder_inputs = Input(shape=(max_english_len,))\n",
    "decoder_embedding = Embedding(input_dim=len_english_word_corpus ,output_dim=latent_dim)(decoder_inputs)\n",
    "decoder_lstm = LSTM(latent_dim ,return_sequences=True ,input_length=decoder_embedding) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "Exception encountered when calling layer 'attention_4' (type Attention).\n\nAttempt to convert a value (<keras.src.layers.rnn.lstm.LSTM object at 0x7fea710559d0>) with an unsupported type (<class 'keras.src.layers.rnn.lstm.LSTM'>) to a Tensor.\n\nCall arguments received by layer 'attention_4' (type Attention):\n  • inputs=['<keras.src.layers.rnn.lstm.LSTM object at 0x7fea710559d0>', '<keras.src.layers.rnn.lstm.LSTM object at 0x7fea710eac90>']\n  • mask=None\n  • training=None\n  • return_attention_scores=False\n  • use_causal_mask=False",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m/home/adarsh/RNN/Attention_model.ipynb Cell 11\u001b[0m line \u001b[0;36m1\n\u001b[0;32m----> <a href='vscode-notebook-cell:/home/adarsh/RNN/Attention_model.ipynb#X14sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m attention \u001b[39m=\u001b[39m Attention()([encoder_lstm, decoder_lstm])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/adarsh/RNN/Attention_model.ipynb#X14sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m context \u001b[39m=\u001b[39m dot([attention, encoder_lstm], axes\u001b[39m=\u001b[39m[\u001b[39m2\u001b[39m, \u001b[39m1\u001b[39m])\n\u001b[1;32m      <a href='vscode-notebook-cell:/home/adarsh/RNN/Attention_model.ipynb#X14sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m decoder_combined_context \u001b[39m=\u001b[39m concatenate([context, decoder_lstm])\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/keras/src/utils/traceback_utils.py:70\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     67\u001b[0m     filtered_tb \u001b[39m=\u001b[39m _process_traceback_frames(e\u001b[39m.\u001b[39m__traceback__)\n\u001b[1;32m     68\u001b[0m     \u001b[39m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m     69\u001b[0m     \u001b[39m# `tf.debugging.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m---> 70\u001b[0m     \u001b[39mraise\u001b[39;00m e\u001b[39m.\u001b[39mwith_traceback(filtered_tb) \u001b[39mfrom\u001b[39;00m \u001b[39mNone\u001b[39;00m\n\u001b[1;32m     71\u001b[0m \u001b[39mfinally\u001b[39;00m:\n\u001b[1;32m     72\u001b[0m     \u001b[39mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/.local/lib/python3.11/site-packages/tensorflow/python/framework/constant_op.py:98\u001b[0m, in \u001b[0;36mconvert_to_eager_tensor\u001b[0;34m(value, ctx, dtype)\u001b[0m\n\u001b[1;32m     96\u001b[0m     dtype \u001b[39m=\u001b[39m dtypes\u001b[39m.\u001b[39mas_dtype(dtype)\u001b[39m.\u001b[39mas_datatype_enum\n\u001b[1;32m     97\u001b[0m ctx\u001b[39m.\u001b[39mensure_initialized()\n\u001b[0;32m---> 98\u001b[0m \u001b[39mreturn\u001b[39;00m ops\u001b[39m.\u001b[39;49mEagerTensor(value, ctx\u001b[39m.\u001b[39;49mdevice_name, dtype)\n",
      "\u001b[0;31mValueError\u001b[0m: Exception encountered when calling layer 'attention_4' (type Attention).\n\nAttempt to convert a value (<keras.src.layers.rnn.lstm.LSTM object at 0x7fea710559d0>) with an unsupported type (<class 'keras.src.layers.rnn.lstm.LSTM'>) to a Tensor.\n\nCall arguments received by layer 'attention_4' (type Attention):\n  • inputs=['<keras.src.layers.rnn.lstm.LSTM object at 0x7fea710559d0>', '<keras.src.layers.rnn.lstm.LSTM object at 0x7fea710eac90>']\n  • mask=None\n  • training=None\n  • return_attention_scores=False\n  • use_causal_mask=False"
     ]
    }
   ],
   "source": [
    "attention = Attention()([encoder_lstm, decoder_lstm])\n",
    "context = dot([attention, encoder_lstm], axes=[2, 1])\n",
    "decoder_combined_context = concatenate([context, decoder_lstm])\n",
    "\n",
    "output = Dense(len_english_word_corpus ,activation=\"softmax\")(decoder_combined_context)\n",
    "\n",
    "model = Model(\n",
    "    inputs=[encoder_inputs,decoder_inputs],\n",
    "    outputs=output\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
